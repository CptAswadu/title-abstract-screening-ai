{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f289af8d8b8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import transformers\n",
    "from io import StringIO\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch\n",
    "#import requests\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148d17c1a7c647d5aa44d3c822ada91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a5a19fbfcd4f5e86f334826f86a591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/50.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880f9ad6a4bb4d388c709e30301b6955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3a2d98b5d3462eb5b4baacbf3ade20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00005.bin:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flanT5tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
    "flanT5 = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\", device_map=\"auto\")\n",
    "flanT5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHNCTokenizer = AutoTokenizer.from_pretrained(\"Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B\")\n",
    "OHNC = AutoModelForCausalLM.from_pretrained(\"Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtralTokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "Mixtral = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Platypus\n",
    "platypusTokenizer = AutoTokenizer.from_pretrained(\"garage-bAInd/Platypus2-7B\")\n",
    "Platypus = AutoModelForCausalLM.from_pretrained(\"garage-bAInd/Platypus2-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setParameters(newLevels, newModel, newPromptAdaption):\n",
    "    global levels, model, promptAdaption\n",
    "    levels = newLevels\n",
    "    model = newModel\n",
    "    promptAdaption = newPromptAdaption\n",
    "\n",
    "\n",
    "levels = 5\n",
    "model = \"flanT5\"\n",
    "promptAdaption = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "setParameters(5, model, False)\n",
    "#Counter\n",
    "startcount=1\n",
    "endcount=-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(prompt, model, systemPrompt):\n",
    "    \n",
    "    \n",
    "    ret=\"No model defined!\"\n",
    "    \n",
    "    if model==\"OHNC\":        \n",
    "        inputs = OHNCTokenizer(prompt+systemPrompt, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        outputs = OHNC.generate(input_ids, \n",
    "                                max_new_tokens=400, \n",
    "                                pad_token_id=OHNCTokenizer.eos_token_id,\n",
    "                                do_sample=False)\n",
    "        ret = OHNCTokenizer.decode(outputs[0])#, skip_special_tokens=True)\n",
    "        ret = ret[len(prompt+systemPrompt):len(ret)]\n",
    "    elif model==\"flanT5\":\n",
    "        input_ids = flanT5tokenizer(prompt+systemPrompt, return_tensors='pt').input_ids.to(\"cuda\")\n",
    "        outputs = flanT5.generate(input_ids, \n",
    "                                max_new_tokens=20,\n",
    "                                num_beams=1)\n",
    "        ret=flanT5tokenizer.decode(outputs[0])\n",
    "    elif model==\"mixtral\":\n",
    "        inputText=\"<s>[INST] {\"+prompt+systemPrompt+\"}[/INST]\"\n",
    "        inputs = mixtralTokenizer(inputText, return_tensors=\"pt\")\n",
    "        outputs = Mixtral.generate(**inputs,\n",
    "                                   max_new_tokens=400)\n",
    "        ret=mixtralTokenizer.decode(outputs[0])\n",
    "        ret = ret[len(inputText)+4:len(ret)]\n",
    "    elif model ==\"platypus\":    \n",
    "        inputs = platypusTokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = Platypus.generate(**inputs,\n",
    "                                    temperature=0,\n",
    "                                    max_new_tokens=20, \n",
    "                                    num_return_sequences=1)\n",
    "\n",
    "        ret = platypusTokenizer.decode(outputs[0])\n",
    "        ret = ret[len(prompt)+4:len(ret)]\n",
    "    if(ret==\"No model defined!\"):\n",
    "        print(ret)   \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899be871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "def testRun(newLevels, newModel, newPromptAdaption, dataset_path):\n",
    "    setParameters(newLevels, newModel, newPromptAdaption)\n",
    "    \n",
    "    saveName = f\"result_L{newLevels}_M{newModel}_PA{newPromptAdaption}\"\n",
    "\n",
    "    # Initialize counters and evaluation arrays\n",
    "    includedCount = 0\n",
    "    notIncludedCount = 0\n",
    "    unclearCount = 0\n",
    "    resultRow = []\n",
    "    \n",
    "    eval = [[0, 0, 0, 0, 0] for _ in range(newLevels - 1)]  # [counts, correctlyIncluded, falselyIncluded, correctlyNotIncluded, falselyNotIncluded]\n",
    "    \n",
    "    for file_name in os.listdir(dataset_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                txt_data = f.read()\n",
    "\n",
    "            # Extract fields based on text structure\n",
    "            name = re.search(r\"'Name': '(.+?)'\", txt_data).group(1) if re.search(r\"'Name': '(.+?)'\", txt_data) else \"N/A\"\n",
    "            pmid = re.search(r\"'PMID': '(\\d+)'\", txt_data).group(1) if re.search(r\"'PMID': '(\\d+)'\", txt_data) else \"N/A\"\n",
    "            pmcid_match = re.search(r\"'PMCID': '(\\S+)'\", txt_data)\n",
    "            selection_criteria = re.search(r\"'Selection_criteria': '(.+?)'\", txt_data)\n",
    "            clinical_questions = re.search(r\"'Clinical_questions': '(.+?)'\", txt_data).group(1) if re.search(r\"'Clinical_questions': '(.+?)'\", txt_data) else \"N/A\"\n",
    "            excluded_studies_match = re.search(r\"'Excluded_studies':\\s*\\[(.*?)\\]\", txt_data, re.DOTALL)\n",
    "            included_studies_match = re.search(r\"'Included_studies':\\s*\\[(.*?)\\]\", txt_data, re.DOTALL)\n",
    "    \n",
    "            # Extract numbers from Excluded Studies and Included Studies\n",
    "            excluded_studies = re.findall(r\"\\d+\", excluded_studies_match.group(1)) if excluded_studies_match else []\n",
    "            included_studies = re.findall(r\"\\d+\", included_studies_match.group(1)) if included_studies_match else []\n",
    "    \n",
    "            # Extracting Excluded Studies Characteristics\n",
    "            excluded_characteristics_match = re.search(r\"'Excluded_Studies_characteristics': \\{(.*?)\\}\", txt_data, re.DOTALL)\n",
    "            excluded_studies_characteristics = {}\n",
    "            if excluded_characteristics_match:\n",
    "                characteristics_data = excluded_characteristics_match.group(1)\n",
    "                # Match each entry in the characteristics dictionary\n",
    "                characteristics_entries = re.findall(r\"'(\\d+)': '(.+?)'\", characteristics_data)\n",
    "                for study_id, characteristic in characteristics_entries:\n",
    "                    excluded_studies_characteristics[study_id] = characteristic\n",
    "            \n",
    "            title = name   \n",
    "            abstract = (\n",
    "                f\"Clinical Questions: {clinical_questions}\\n\"\n",
    "                f\"Selection Criteria: {selection_criteria}\\n\"\n",
    "                f\"Included Studies: {', '.join(included_studies) if included_studies else 'None'}\\n\"\n",
    "                f\"Excluded Studies: {', '.join(excluded_studies) if excluded_studies else 'None'}\\n\"\n",
    "                f\"Excluded Studies Characteristics: {excluded_studies_characteristics if excluded_studies_characteristics else 'None'}\"\n",
    "            )\n",
    "            included_label = \"1\"  \n",
    "\n",
    "            # Prompt setup\n",
    "            digitString = \", \".join(map(str, range(1, newLevels))) + f\" or {newLevels}\"\n",
    "            instruction = f\"On a scale from 1 (very low) to {newLevels} (very high), rate the relevance based on title, abstract, and criteria.\"\n",
    "            prompt = f\"{instruction} Title: {title}, Abstract: {abstract}, Relevant criteria: {relevantCriteria}\"\n",
    "\n",
    "            answer = getAnswer(prompt, newModel, instruction)\n",
    "            answer = int(re.search(r'\\d+', answer).group()) if re.search(r'\\d+', answer) else -1\n",
    "\n",
    "            # Count as unclear if answer is out of bounds\n",
    "            if answer < 1 or answer > newLevels:\n",
    "                unclearCount += 1\n",
    "                continue\n",
    "\n",
    "            # Store result\n",
    "            singleResult = [file_name, title, abstract, included_label, answer, prompt]\n",
    "            resultRow.append(singleResult)\n",
    "\n",
    "            if included_label == \"1\":\n",
    "                includedCount += 1\n",
    "                for i in range(newLevels - 1):\n",
    "                    if newLevels - i == answer:\n",
    "                        eval[i][0] += 1  # Increase counter\n",
    "                    if newLevels - i <= answer:\n",
    "                        eval[i][1] += 1  # Correctly included\n",
    "                    else:\n",
    "                        eval[i][4] += 1  # Incorrectly not included\n",
    "            else:\n",
    "                notIncludedCount += 1\n",
    "                for i in range(newLevels - 1):\n",
    "                    if newLevels - i == answer:\n",
    "                        eval[i][0] += 1  # Increase counter\n",
    "                    if newLevels - i <= answer:\n",
    "                        eval[i][2] += 1  # Falsely included\n",
    "                    else:\n",
    "                        eval[i][3] += 1  # Correctly not included\n",
    "\n",
    "            # Intermediate save\n",
    "            with open(f\"{saveName}_single.csv\", 'a', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f, delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "                writer.writerow(singleResult)\n",
    "\n",
    "    # Final output and evaluation metrics\n",
    "    with open(f\"{saveName}.csv\", 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        header = [\"File Name\", \"Title\", \"Abstract\", \"Included-Label\", \"LLM Answer\", \"Prompt\"]\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(resultRow)\n",
    "\n",
    "        # Metrics Calculation\n",
    "        tp, sensitivity, precision, recall, f1, specificity = ([] for _ in range(6))\n",
    "        for i in range(newLevels - 1):\n",
    "            tp.append(eval[i][1] / eval[i][0] if eval[i][0] > 0 else -1)\n",
    "            sensitivity.append(eval[i][1] / includedCount if includedCount > 0 else -1)\n",
    "            precision.append(eval[i][1] / (eval[i][1] + eval[i][2]) if (eval[i][1] + eval[i][2]) > 0 else -1)\n",
    "            recall.append(eval[i][1] / (eval[i][1] + eval[i][4]) if (eval[i][1] + eval[i][4]) > 0 else -1)\n",
    "            f1.append(2 * ((precision[i] * recall[i]) / (precision[i] + recall[i])) if (precision[i] + recall[i]) > 0 else -1)\n",
    "            specificity.append(eval[i][3] / notIncludedCount if notIncludedCount > 0 else -1)\n",
    "\n",
    "            # Output metrics for each level in the file\n",
    "            writer.writerow([\"Metric\", f\"Level {newLevels - i}\"])\n",
    "            writer.writerow([\"True Positive Rate\", tp[i]])\n",
    "            writer.writerow([\"Sensitivity\", sensitivity[i]])\n",
    "            writer.writerow([\"Specificity\", specificity[i]])\n",
    "            writer.writerow([\"Precision\", precision[i]])\n",
    "            writer.writerow([\"Recall\", recall[i]])\n",
    "            writer.writerow([\"F1-Score\", f1[i]])\n",
    "\n",
    "    # Print summary information\n",
    "    print(f\"Included Publications: {includedCount}\")\n",
    "    print(f\"Unclear Count: {unclearCount}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def testRun(newLevels, newModel, newPromptAdaption, dataset):\n",
    "    setParameters(newLevels, newModel, newPromptAdaption)\n",
    "    if dataset==\"CDSS_in_RO\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        -Only inclusion of original articles, exclusion of review articles\n",
    "        -Publications examining one or several clinical decision-support systems relevant for radiation therapy\n",
    "        -Decision-support systems are software based\n",
    "        -Exclusion of systems intended for support of non-clinicians (e.g. patient decision-aids)\n",
    "        -Publications about models (e.g. prognostic models) should only be included, if the model is intended to support clinical decision-making as part of a software application, which may resemble a clinical decision support system\n",
    "        \"\"\"\n",
    "    elif dataset==\"Appenzeller-Herzog\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        -Patients with Wilson's Disease of any age or stage \n",
    "        -Study drug has to be one of four established therapies, namely DPen, trientine, TTM or Zn.\n",
    "        -Control could be placebo, no treatment or any other treatment that does not include the respective study drug \n",
    "        -Concomitant therapies had to be identical in the compared treatment arms\n",
    "        -Combination therapy regimens that include the respective monotherapy drug are not considered\n",
    "        -Prospective or retrospective studies reported \n",
    "        -Randomized, non-randomized controlled trials and comparative observational studies\n",
    "        -Animal studies, case reports, case series, cross‐sectional studies, before‐after studies, reviews, letters, abstract‐only publications, editorials, \n",
    "        diagnostic or other testing studies and non‐controlled studies are excluded\n",
    "        \"\"\"\n",
    "    elif dataset==\"Wolters\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        -Prospective studies of humans that report the risk of all-cause dementia or Alzheimer's disease in relation to coronary heart disease or congestive heart failure\n",
    "        -Only original articles\n",
    "        \"\"\"\n",
    "    elif dataset==\"Bos_2018\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Inclusion criteria: (1) all studies have to be prospective\n",
    "        population-based cohort studies. Inherent to the nature of\n",
    "        population-based studies this means that except for a\n",
    "        selection criterion of age, no other selection criteria are\n",
    "        applied; (2) cerebral imaging had to be performed\n",
    "        (either magnetic resonance imaging [MRI] or computed\n",
    "        tomography) for the visualization of white matter\n",
    "        hyperintensities, covert brain infarcts, or microbleeds; (3) all\n",
    "        studies have to have investigated the association of any of the\n",
    "        three pathologies with the risk of incident all-dementia or\n",
    "        Alzheimer’s disease.\n",
    "        \"\"\"\n",
    "    elif dataset==\"Brouwer_2019\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Criteria for studies to be included in the review are: (1) Presence\n",
    "        of a diagnostic status of major depressive disorder (MDD) (MDD absence and/or presence) for all\n",
    "        participants, as determined through a clinical interview or by a clinician at the start of the\n",
    "        study; (2) At some point during the study, participants needed to be in\n",
    "        (partial) remission or recovery as determined by a clinical interview or\n",
    "        clinician assessment; and (3) relapse or recurrence was diagnosed\n",
    "        through a clinical interview or by a clinician. (4) The study design was\n",
    "        longitudinal and prospective; (5) The theory-derived predictor (i.e., the\n",
    "        proposed factors) was assessed before the relapse or recurrence of MDD;\n",
    "        (6) The predictor was derived from one of the leading psychological\n",
    "        theories; (7) Sufficient information was reported to calculate effect sizes\n",
    "        (or was made available upon request). Exclusion criteria are the\n",
    "        presence of bipolar disorder, dysthymia, seasonal affective disorder,\n",
    "        postpartum depression, late-life MDD, or MDD due to medical disorders. Studies that solely included people with a first onset MDD when\n",
    "        they were older than 65 years, were excluded due to potential etiological differences between late-life onset MDD and MDD at younger ages\n",
    "        \"\"\"\n",
    "    elif dataset==\"Donners_2021\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        The following inclusion criteria are applied: emicizumab\n",
    "        studies providing (1) data on humans, (2) original PK data or\n",
    "        modeled PK data or PK/PD relationships, and (3) access to\n",
    "        the abstract and the full text in English. In the event of doubt\n",
    "        regarding eligibility, the records or articles should be included.\n",
    "        \"\"\"\n",
    "    elif dataset==\"Jeyaraman_2021\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Inclusion Criteria\n",
    "        Studies are included if they meet the following PICOS criteria:\n",
    "        Population: Patients with knee osteoarthritis\n",
    "        Intervention: MSC therapy\n",
    "        Comparator: Usual care\n",
    "        Outcomes: Visual Analog Score (VAS) for Pain, Western Ontario McMaster Universities Osteoarthritis Index (WOMAC), Lysholm Knee Scale (Lysholm), Whole-Organ Magnetic Resonance Imaging Score (WORMS), Knee Osteoarthritis Outcome Score (KOOS), and adverse events\n",
    "        Study Design: Randomized controlled trials\n",
    "        Exclusion Criteria\n",
    "        Trials are excluded if they had the following characteristics:\n",
    "        1. Observational studies and interventional studies without a comparator group\n",
    "        2. Animal studies involving stem cell therapy for knee osteoarthritis models\n",
    "        3. Review\n",
    "        \"\"\"\n",
    "    elif dataset==\"Leenaars_2019\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Exclusion of (1) studies on other techniques than microdialysis\n",
    "        (e.g. biosensors and microdialysis precursors such\n",
    "        as push-pull perfusion), (2) studies measuring other substances\n",
    "        than Hist and the amino acids Asn, Asp, GABA,\n",
    "        Glu, Gln, Gly, Pro and Tau, (3) retro-dialysis studies, (4)\n",
    "        microdialysis studies that did not report baseline values\n",
    "        without the specified molecules in the perfusion fluid,\n",
    "        (5) extra-cerebral microdialysis studies, (6) human and in\n",
    "        vitro studies, and (7) papers not containing primary study\n",
    "        data. Within publications, experiments using techniques\n",
    "        other than microdialysis are also ignored, as\n",
    "        well as data on amino acids other than those searched for.\n",
    "        During screening, tags were added by KJ and CL to all\n",
    "        studies on circadian rhythms, sleep and sleep deprivation.\n",
    "        Studies on circadian rhythms, sleep and sleep deprivation are included based on the following criterion: \n",
    "        studies measuring one\n",
    "        or more of the molecules of interest during (1) naturally\n",
    "        occurring sleep stages that were validated with polysomnographic\n",
    "        measurements and/or (2) during sleep deprivation.\n",
    "        Studies on e.g. carbachol-induced REM-sleep are\n",
    "        thus excluded.\n",
    "        \"\"\"\n",
    "    elif dataset==\"Leenaars_2020\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Inclusion of all studies in which methotrexat (MTX) was administered to rheumatoid arthritis (RA) patients or RA animal models. \n",
    "        Exclusion of studies on other diseases than RA, studies that were not in vivo,\n",
    "        studies that did not administer MTX (or only had treatment groups co-administering MTX with other\n",
    "        experimental drugs), studies that did not analyse efficacy (e.g., safety studies), and publications that\n",
    "        do not contain new data (e.g., reviews and editorials).\n",
    "        \"\"\"\n",
    "    elif dataset==\"Meijboom_2021\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Articles are included if they meet the\n",
    "        following criteria: (1) study involved transitioning from a\n",
    "        TNF-alpha inhibitor (including etanercept, infliximab, and adalimumab)\n",
    "        originator to a biosimilar, (2) the number of patients\n",
    "        who retransitioned is reported or can be calculated, (3)\n",
    "        the article is an original research article published in a\n",
    "        peer-reviewed journal, (4) the article included baseline\n",
    "        characteristics of the patients who transitioned, (5) the article\n",
    "        is written in English. Transitioning is defined as\n",
    "        patients in whom the biosimilar was introduced after the \n",
    "        originator, without treatment with other drugs in between.\n",
    "        Retransitioning is defined as restarting the originator\n",
    "        directly after discontinuing a biosimilar, without treatment\n",
    "        with other drugs in between. In summary, transitioning is\n",
    "        defined as switching from the originator to a biosimilar;\n",
    "        retransitioning is defined as switching from the originator\n",
    "        to a biosimilar and back to the originator. Both transitioning\n",
    "        and retransitioning involve changes with the same active\n",
    "        biological substance.\n",
    "        \"\"\"\n",
    "    elif dataset==\"Moran_2021\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Original experimental studies\n",
    "        that manipulated the condition of animals in independent\n",
    "        treatment groups through their diet, via both dietary quantity\n",
    "        (i.e. partial restriction, complete deprivation or enrichment)\n",
    "        or quality treatments (e.g. protein restriction or enrichment),\n",
    "        and including both short-term and longer-term manipulations\n",
    "        up to extended periods of weeks to months. Studies that then subjected those animals to\n",
    "        behavioural observations in contexts relating to risk\n",
    "        (e.g. novel environments, novel object, risk-sensitive foraging,\n",
    "        predator response) in independent trials.\n",
    "        Inclusion criteria (all need to be true):\n",
    "        -Topic is in a potentially relevant field (e.g., biology, ecology, psychology)\n",
    "        -Paper contains original empirical data\n",
    "        -Study species is a non-human, non-genetically modified animal\n",
    "        -Study includes an experimental manipulation of animal´s nutritional or energetic state\n",
    "        -Dietary manipulations (a) in the current generation, (b) not limited only to specific compounds/chemicals (e.g., omega-3 fatty acids), and (c) not limited to temporal/spatially variability in food\n",
    "        -Behavioural response variables that are related to risk (e.g., predator response, novel environment/object, risk sensitive foraging)\n",
    "        \"\"\"\n",
    "    elif dataset==\"Muthu_2021\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Inclusion Criteria\n",
    "        To be included, a study should meet the\n",
    "        following criteria:\n",
    "        1. The study should be an RCT with 1:1 parallel twoarm\n",
    "        design.\n",
    "        2. The study must be related to spine surgery involving\n",
    "        preoperative or intraoperative or postoperative variables.\n",
    "        3. The study must have a dichotomous primary or\n",
    "        secondary outcome.\n",
    "        Exclusion Criteria\n",
    "        1. Studies not involving human subjects.\n",
    "        2. Studies with continuous variable outcomes like pain\n",
    "        scores, Oswestry Disability Index scores, time to\n",
    "        union without predefined clinical success criteria.\n",
    "        3. Studies that did not report a statistically significant\n",
    "        primary or secondary outcome measure.\n",
    "        \"\"\"\n",
    "    elif dataset==\"Oud_2018\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Randomized controlled trials (RCT)s on four specialized psychotherapies\n",
    "        (DBT: dialectic behavior therapy, MBT: mentalization-based treatment, TFP: transference-focused therapy and ST: schema therapy) \n",
    "        for adults (18 years and older)\n",
    "        with Borderline personality disorder (BPD), which includes an individual psychotherapy\n",
    "        component and had a duration of 16 weeks or more.\n",
    "        Eligible comparison groups are other protocolized and\n",
    "        specialized psychotherapies, or control groups, for\n",
    "        example, treatment as usual (TAU), waiting list, attention\n",
    "        control or community treatment by experts (CTBE).\n",
    "        Studies are excluded with a cut-off of <66% of the participants\n",
    "        having BPD, unless disaggregated data are provided. Studies are excluded that tested incomplete\n",
    "        versions of specialized treatment, for example,\n",
    "        studies that investigated only skills training instead of\n",
    "        the full DBT program.\n",
    "        \"\"\"\n",
    "    elif dataset==\"van_de_Schoot_2018\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        (a) longitudinal studies with at least three measurement\n",
    "        waves measuring posttraumatic stress disorder (PTSD), (b) studies that measured PTSD on a\n",
    "        continuous scale via an interviewor questionnaire, (c) and studies\n",
    "        that used a clustering method (Latent growth mixture modelling, hierarchical\n",
    "        cluster analysis), (d) traumatic stress symptoms following events\n",
    "        that appeared to fulfill DSM-IV criterion A1 for PTSD or acute\n",
    "        stress disorder.\n",
    "        \"\"\"\n",
    "    elif dataset==\"van_der_Valk_2021\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Studies that report original Long-term glucocorticoids (HairGC) data.\n",
    "        \"\"\"\n",
    "    elif dataset==\"van_Dis_2020\":\n",
    "        startcount=1\n",
    "        endcount=-1\n",
    "        relevantCriteria=\"\"\"\n",
    "        Randomized clinical trials are included that examined effects of cognitive behavioral therapy \n",
    "        (CBT; ie, any therapy with cognitive restructuring and/or a behavioral therapy, such as exposure, as core component),\n",
    "        including third generation CBTs (ie, acceptance and commitment therapy and metacognitive therapy), at least 1 month after treatment completion,\n",
    "        in an individual, group, or internet treatment format. Comparison groups include care as usual\n",
    "        (ie, anything patients would normally receive as long as it was not a structured type of psychotherapy, such as primary care at \n",
    "        medical centers or case management with educational groups),15 relaxation, psychoeducation, pill placebo, supportive therapy, or \n",
    "        waiting list. Studies are included if they tested adult patients (or samples consisting mostly of adults but also some adolescents \n",
    "        aged ≥16 years) who received a diagnosis of generalized anxiety disorder, agoraphobia, social anxiety disorder, specific phobia, posttraumatic stress disorder, \n",
    "        or obsessive-compulsive disorder based on results of a structured diagnostic interview.\n",
    "        Studies are excluded if they do not use CBT (eg, applied relaxation, eye movement desensitization and reprocessing, or interpersonal therapy) \n",
    "        or do not report symptoms separately for each disorder. To reduce clinical heterogeneity, studies were also excluded if they had done any of \n",
    "        the following: (1) used self-guided therapy without any guidance, (2) used CBT combined with medication or pill placebo, or (3) tested inpatients.\n",
    "        \"\"\"\n",
    "    saveName = \"result_L\"+str(levels)+\"_M\"+model+\"_PA\"+str(promptAdaption)\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"dataset(\"+dataset+\").csv\", 'r', encoding='ISO-8859-1') as file:\n",
    "        reader = csv.reader(file, delimiter=';')\n",
    "        readerlist = list(reader)\n",
    "        count = 0\n",
    "        includedCount = 0\n",
    "        notIncludedCount = 0\n",
    "        eval = []         \n",
    "        for i in range(levels - 1):\n",
    "            eval.append([0,0,0,0,0])\n",
    "        unclearCount=0\n",
    "        resultRow=[]\n",
    "        digitString = str(levels - 1) + \" or \" + str(levels) # shall be \"1, 2, 3, 4 or 5\" in the end\n",
    "        for i in range(levels - 2, 0, -1):\n",
    "            digitString = str(i) + \", \" + digitString\n",
    "\n",
    "\n",
    "        systemPrompt=\"You evaluate the relevance of scientific publications based on named criteria and based on title and abstract of a publication. Your answer consists only of a single digit (\" + digitString + \"). Do not include further explanation.\"\n",
    "\n",
    "        highScoreText = str(levels) + \"\"\n",
    "        if levels >= 5:\n",
    "            highScoreText = str(levels - 1) + \" or \" + str(levels)\n",
    "        if levels >= 10:\n",
    "            highScoreText = str(levels - 2) + \", \" + str(levels - 1) + \" or \" + str(levels)\n",
    "\n",
    "        instruction=\"On a scale from 1 (very low probability) to \" + str(levels) + \" (very high probability), how would you rate the relevance of the scientific publication for inclusion into a systematic literature review based on the relevant criteria and based on title and abstract?\"\n",
    "        if promptAdaption==True:\n",
    "            instruction=instruction+\"(Note: Give a low score if not all criteria are fulfilled. Give only a high score if all or almost all criteria are fulfilled.)\"\n",
    "\n",
    "\n",
    "        count -= 1 #reduce count by one because it is increased right at the start of the for loop (instead of in the end because we have a 'continue' in the code)\n",
    "        for row in readerlist:\n",
    "\n",
    "            count+=1\n",
    "            if count > endcount and endcount != -1: #if endcount is -1, there is no endcount\n",
    "                break\n",
    "\n",
    "            if count>=startcount:\n",
    "                if count!=0:\n",
    "                    title = row[0]\n",
    "                    abstract = row[1]\n",
    "                    included_label = row[2]\n",
    "                    #Scale prompt\n",
    "                    prompt=instruction\n",
    "                    prompt=prompt+\" Title: \"+title+\", Abstract: \"+abstract+\", Relevant criteria: \"+relevantCriteria\n",
    "                    \n",
    "                    print(\"Count:\"+str(count))\n",
    "                    sumOfAnswers = 0\n",
    "                    validRuns = 0\n",
    "                    individualAnswers = []\n",
    "                    error=True\n",
    "\n",
    "\n",
    "                    if model==\"OHNC\" or model==\"flanT5\" or model==\"mixtral\" or model==\"platypus\":\n",
    "                        answer = getAnswer(prompt,model,systemPrompt)\n",
    "                        print(\"Answer:\"+answer)\n",
    "                        llmresponse=answer\n",
    "                        regexFilter=re.search(r'\\d+', answer)\n",
    "                        if isinstance(regexFilter,type(None)):\n",
    "                            answer=-1\n",
    "                        else:\n",
    "                            answer=re.search(r'\\d+', answer).group()\n",
    "                            answer=int(answer)\n",
    "                        print(\"Result:\"+str(answer))\n",
    "\n",
    "\n",
    "                    if answer < 1 or answer > levels:\n",
    "                        answer = -1\n",
    "\n",
    "\n",
    "                    if answer >= 1 and answer <= levels:\n",
    "                        sumOfAnswers += int(answer)\n",
    "                        validRuns += 1\n",
    "                    \n",
    "                if validRuns == 0:\n",
    "                    unclearCount += 1 #otherwise no answer was found and it is skipped\n",
    "                    print(\"Skipped '\" + title + \"' because the answer was invalid.\")\n",
    "                        #continue\n",
    "                else:\n",
    "                    answer = float(sumOfAnswers / validRuns) #compute average answer\n",
    "\n",
    "                singleResult=[]\n",
    "                singleResult.append(str(count))\n",
    "                singleResult.append(title)\n",
    "                singleResult.append(abstract)\n",
    "                singleResult.append(included_label)\n",
    "                singleResult.append(answer)\n",
    "                singleResult.append(llmresponse)\n",
    "                for i in individualAnswers:\n",
    "                    singleResult.append(i)\n",
    "\n",
    "\n",
    "\n",
    "                with open(saveName+\"(single).csv\",'a',newline='',encoding='utf-8') as f:\n",
    "                    writer = csv.writer(f , delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "                    writer.writerow(singleResult)\n",
    "\n",
    "\n",
    "                resultRow.append(singleResult)\n",
    "\n",
    "                \n",
    "                if included_label==\"1\":  \n",
    "                    includedCount+=1\n",
    "\n",
    "                    for i in range(levels - 1):\n",
    "                        if (levels - i == answer):\n",
    "                            eval[i][0] += 1 #increase counter\n",
    "                        if (levels - i <= answer):\n",
    "                            eval[i][1] += 1 #correctly included\n",
    "                        else:\n",
    "                            eval[i][4] += 1 #incorrectly included\n",
    "\n",
    "                else:\n",
    "                    notIncludedCount+=1\n",
    "\n",
    "                    for i in range(levels - 1):\n",
    "                        if (levels - i == answer):\n",
    "                            eval[i][0] += 1 #increase counter\n",
    "                        if (levels - i <= answer):\n",
    "                            eval[i][2] += 1 #falsely included\n",
    "                        else:\n",
    "                            eval[i][3] += 1 #correctly not included\n",
    "            \n",
    "\n",
    "    # [number of counts, correctlyIncluded, falselyIncluded, correctlyNotIncluded, falselyNotIncluded]\n",
    "    print(\"Included Publications: \",includedCount)\n",
    "\n",
    "    for i in range(levels - 1):\n",
    "        print(\"Totally Included (answer=\"+str(levels-i)+\"): \",str(eval[i][0]))\n",
    "        print(\"Correctly Included (answer=\"+str(levels-i)+\"): \",str(eval[i][1]))\n",
    "        print(\"Correctly Not Included (answer=\"+str(levels-i)+\"): \",str(eval[i][3]))\n",
    "        print(\"Falsely Included (answer=\"+str(levels-i)+\"): \",str(eval[i][2]))\n",
    "        print(\"Falsely Not Included (answer=\"+str(levels-i)+\"): \",str(eval[i][4]))\n",
    "\n",
    "    print(\"UnclearCount: \",unclearCount)\n",
    "\n",
    "\n",
    "    # init evaluation arrays\n",
    "    tp = []\n",
    "    sensitivity = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    specifity = []\n",
    "    for i in range(levels - 1):\n",
    "        tp.append(0)\n",
    "        sensitivity.append(0)\n",
    "        precision.append(0)\n",
    "        recall.append(0)\n",
    "        f1.append(0)\n",
    "        specifity.append(0)\n",
    "\n",
    "    # do evaluation\n",
    "    if includedCount>0:\n",
    "        #tp=true positive only for this score\n",
    "        prevEval1 = 0\n",
    "        for i in range(levels - 1):\n",
    "            if eval[i][0] > 0:\n",
    "                tp[i] = (eval[i][1] - prevEval1) / eval[i][0]\n",
    "            else:\n",
    "                tp[i] = -1\n",
    "            prevEval1 = eval[i][1]\n",
    "\n",
    "            sensitivity[i] = eval[i][1] / includedCount\n",
    "\n",
    "            if (eval[i][1] + eval[i][2]) > 0:\n",
    "                precision[i] = eval[i][1] / (eval[i][1]+eval[i][2])\n",
    "            else:\n",
    "                precision[i] = -1\n",
    "            \n",
    "            if (eval[i][1] + eval[i][4]) > 0:\n",
    "                recall[i] = eval[i][1] / (eval[i][1] + eval[i][4])\n",
    "            else:\n",
    "                recall[i] = 1\n",
    "            \n",
    "            if (precision[i] + recall[i]) > 0:\n",
    "                f1[i] = 2 * ((precision[i] * recall[i]) / (precision[i] + recall[i]))\n",
    "            else:\n",
    "                f1[i] = -1\n",
    "            \n",
    "            specifity[i] = eval[i][3] / notIncludedCount\n",
    "    else:\n",
    "        for i in range(levels - 1):\n",
    "            sensitivity[i] = -1\n",
    "            precision[i] = -1\n",
    "            recall[i] = -1\n",
    "            f1[i] = -1\n",
    "            specifity[i] = -1\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(levels - 1):\n",
    "        print(\"True Positive (answer=\"+str(levels-i)+\"): \",str(tp[i]))\n",
    "        print(\"Sensitivity (answer=\"+str(levels-i)+\"): \",str(sensitivity[i]))\n",
    "        print(\"Specificity (answer=\"+str(levels-i)+\"): \",str(specifity[i]))\n",
    "        print(\"Precision (answer=\"+str(levels-i)+\"): \",str(precision[i]))\n",
    "        print(\"Recall (answer=\"+str(levels-i)+\"): \",str(recall[i]))\n",
    "        print(\"F1-Score (answer=\"+str(levels-i)+\"): \",str(f1[i]))\n",
    "\n",
    "\n",
    "    #Add empty line for results\n",
    "    resultRow.append([])\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"System Prompt\")\n",
    "    singleResult.append(systemPrompt)\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Instruction Prompt\")\n",
    "    singleResult.append(instruction)\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"relevantCriteria Prompt\")\n",
    "    singleResult.append(relevantCriteria)\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Levels:\")\n",
    "    singleResult.append(levels)\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Add empty line for results\n",
    "    resultRow.append([])\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Included Publications\")\n",
    "    singleResult.append(includedCount)\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Correctly Included\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(eval[i][1])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Correctly NotIncluded\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(eval[i][3])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Falsely Included\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(eval[i][2])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Falsely NotIncluded\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(eval[i][4])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Unclear Count\")\n",
    "    singleResult.append(unclearCount)\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"True positive\")\n",
    "    for i in range(levels, 1, -1):\n",
    "        singleResult.append(str(i))\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(tp[i])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Sensitivity\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(sensitivity[i])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Specificity\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(specifity[i])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Precision\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(precision[i])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"Recall\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(recall[i])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"F1-Score\")\n",
    "    singleResult.append(str(levels))\n",
    "    for i in range(levels - 1, 1, -1):\n",
    "        singleResult.append(str(i) + \"+\")\n",
    "    resultRow.append(singleResult)\n",
    "    singleResult=[]\n",
    "    singleResult.append(\"\")\n",
    "    for i in range(levels - 1):\n",
    "        singleResult.append(f1[i])\n",
    "    resultRow.append(singleResult)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open(saveName+\".csv\",'a',newline='',encoding='utf-8') as f:\n",
    "        writer = csv.writer(f , delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        header=[]\n",
    "        header.append(\"No\")\n",
    "        header.append(\"Title\")\n",
    "        header.append(\"Abstract\")\n",
    "        # header.append(\"DOI\")\n",
    "        header.append(\"Included-Label\")\n",
    "        header.append(\"Answer of LLM\")\n",
    "        header.append(\"LLM-Response\")\n",
    "\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(resultRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:1\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:2\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:3\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:4\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:5\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:6\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:7\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:8\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:9\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:10\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:11\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:12\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:13\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:14\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:15\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:16\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:17\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:18\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:19\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:20\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:21\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:22\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:23\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:24\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:25\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:26\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:27\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:28\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:29\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:30\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:31\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:32\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:33\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:34\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:35\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:36\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:37\n",
      "Answer:<pad> 2</s>\n",
      "Result:2\n",
      "Count:38\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:39\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:40\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:41\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:42\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:43\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:44\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:45\n",
      "Answer:<pad> 2</s>\n",
      "Result:2\n",
      "Count:46\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:47\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:48\n",
      "Answer:<pad> 2</s>\n",
      "Result:2\n",
      "Count:49\n",
      "Answer:<pad> 4</s>\n",
      "Result:4\n",
      "Count:50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testRun(\u001b[38;5;241m5\u001b[39m, model, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCDSS_in_RO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 332\u001b[0m, in \u001b[0;36mtestRun\u001b[0;34m(newLevels, newModel, newPromptAdaption, dataset)\u001b[0m\n\u001b[1;32m    328\u001b[0m error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOHNC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflanT5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixtral\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplatypus\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 332\u001b[0m     answer \u001b[38;5;241m=\u001b[39m getAnswer(prompt,model,systemPrompt)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39manswer)\n\u001b[1;32m    334\u001b[0m     llmresponse\u001b[38;5;241m=\u001b[39manswer\n",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m, in \u001b[0;36mgetAnswer\u001b[0;34m(prompt, model, systemPrompt)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflanT5\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m    \u001b[38;5;66;03m# promptJSON={\"inputs\": prompt+systemPrompt, \"parameters\": {\"seed\": 42}}\u001b[39;00m\n\u001b[1;32m     25\u001b[0m    \u001b[38;5;66;03m# response = query(\"https://wyal4oh85pleah2v.us-east-1.aws.endpoints.huggingface.cloud\",promptJSON)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m  \u001b[38;5;66;03m#   print(response)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#    ret = response\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m flanT5tokenizer(prompt\u001b[38;5;241m+\u001b[39msystemPrompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m flanT5\u001b[38;5;241m.\u001b[39mgenerate(input_ids, \n\u001b[1;32m     40\u001b[0m                             max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     41\u001b[0m                             num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m     ret\u001b[38;5;241m=\u001b[39mflanT5tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixtral\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#via TogetherAI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m#print(response)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#ret = response\u001b[39;00m\n",
      "File \u001b[0;32m/data/JH/miniconda3/envs/llms/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/data/JH/miniconda3/envs/llms/lib/python3.11/site-packages/transformers/generation/utils.py:1576\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assisted_decoding(\n\u001b[1;32m   1560\u001b[0m         input_ids,\n\u001b[1;32m   1561\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1573\u001b[0m     )\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1576\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_greedy_search(\n\u001b[1;32m   1577\u001b[0m         input_ids,\n\u001b[1;32m   1578\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   1579\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   1580\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m   1581\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[1;32m   1582\u001b[0m         output_logits\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_logits,\n\u001b[1;32m   1583\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[1;32m   1584\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   1585\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1587\u001b[0m     )\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/data/JH/miniconda3/envs/llms/lib/python3.11/site-packages/transformers/generation/utils.py:2548\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2541\u001b[0m         streamer\u001b[38;5;241m.\u001b[39mput(next_tokens\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m   2542\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   2543\u001b[0m         outputs,\n\u001b[1;32m   2544\u001b[0m         model_kwargs,\n\u001b[1;32m   2545\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2546\u001b[0m     )\n\u001b[0;32m-> 2548\u001b[0m     unfinished_sequences \u001b[38;5;241m=\u001b[39m unfinished_sequences \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m~\u001b[39mstopping_criteria(input_ids, scores)\n\u001b[1;32m   2549\u001b[0m     this_peer_finished \u001b[38;5;241m=\u001b[39m unfinished_sequences\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streamer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data/JH/miniconda3/envs/llms/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:169\u001b[0m, in \u001b[0;36mStoppingCriteriaList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m is_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), \u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m criteria \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m is_done \u001b[38;5;241m|\u001b[39m criteria(input_ids, scores, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_done\n",
      "File \u001b[0;32m/data/JH/miniconda3/envs/llms/lib/python3.11/site-packages/transformers/generation/stopping_criteria.py:160\u001b[0m, in \u001b[0;36mEosTokenCriteria.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    152\u001b[0m         input_ids[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     is_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39misin(input_ids[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id\u001b[38;5;241m.\u001b[39mto(input_ids\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_done\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#testRun(5, model, False, \"CDSS_in_RO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
